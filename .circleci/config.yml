---
version: 2.1
orbs: null
# commands:
  # destroy_environment:
  #   steps:
  #     - run:
  #         name: Destroy environment
  #         when: on_fail
  #         command: |
  #           aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}
jobs:
  # create_infrastructure:
  #   docker:
  #     - image: amazon/aws-cli
  #   steps:
  #     - checkout
  #     - run:
  #         name: Create Cloudformation Stack
  #         command: |
  #           aws cloudformation deploy \
  #             --template-file template.yml \
  #             --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
  #             --region us-east-1
  #     - run:
  #         name: Getting Public IP from EC2 to inventory
  #         command: |
  #           aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --output text >> inventory  

  # configure_infrastructure:
  #   docker:
  #     - image: python:3.7-alpine3.16
  #   steps:
  #     - checkout
  #     - add_ssh_keys:
  #         fingerprints:
  #           - d8:93:b6:0a:e4:73:07:cd:f4:14:0f:1b:12:f3:53:6e
  #     - run:
  #         name: Install Ansible
  #         command: |
  #           apk add --update ansible
  #     - run:
  #         name: Run Playbook and Configure server
  #         command: |
  #           ansible-playbook -i inventory main-remote.yml
  # smoke_test:
  #   docker:
  #     - image: alpine:latest
  #   steps:
  #     - run: apk add --update curl
  #     - run:
  #         name: smoke test
  #         command: |
  #           URL="https://blog.udacity.com/"
  #             # Test if website exists
  #             if curl -s --head ${URL} 
  #             then
  #               return 0
  #             else
  #               return 1
  #             fi
  #     - destroy_environment   
  # Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
      # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
      - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete
  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt   

      # Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
    # Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"  
  # Destroy the previous production version's S3 bucket and CloudFormation stack. 
  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous S3 bucket and CloudFormation stack. 
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive
     
workflows:
  myWorkflow:
    jobs:
      # - create_infrastructure
      # - configure_infrastructure
      # - smoke_test
      - create_and_deploy_front_end
        - promote_to_production:
            requires: 
              - create_and_deploy_front_end
        - get_last_deployment_id
        - clean_up_old_front_end:
            requires:
              - get_last_deployment_id
              - promote_to_production
